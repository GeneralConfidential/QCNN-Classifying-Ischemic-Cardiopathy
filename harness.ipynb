{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:06:33.267411: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-07 15:06:33.268710: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-07 15:06:33.294725: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-07 15:06:33.295421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-07 15:06:33.778477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/raag/sdp/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.12.0\n",
      "GPU Available: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:06:35.113777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-07 15:06:35.114118: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Check hardware resources\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess datasets\n",
    "def load_plantdoc():\n",
    "    \"\"\"Load and preprocess the PlantDoc dataset.\"\"\"\n",
    "    classes = sorted([\n",
    "        'Apple Scab Leaf', 'Apple leaf', 'Apple rust leaf', 'Bell_pepper leaf', 'Bell_pepper leaf spot',\n",
    "        'Blueberry leaf', 'Cherry leaf', 'Corn Gray leaf spot', 'Corn leaf blight', 'Corn rust leaf',\n",
    "        'Peach leaf', 'Potato leaf early blight', 'Potato leaf late blight', 'Raspberry leaf',\n",
    "        'Soyabean leaf', 'Squash Powdery mildew leaf', 'Strawberry leaf', 'Tomato Early blight leaf',\n",
    "        'Tomato Septoria leaf spot', 'Tomato leaf', 'Tomato leaf bacterial spot', 'Tomato leaf late blight',\n",
    "        'Tomato leaf mosaic virus', 'Tomato leaf yellow virus', 'Tomato mold leaf',\n",
    "        'Tomato two spotted spider mites leaf', 'grape leaf', 'grape leaf black rot'\n",
    "    ])\n",
    "    num_classes = len(classes)\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    \n",
    "    def load_images_from_folder(folder):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for class_name in os.listdir(folder):\n",
    "            class_folder = os.path.join(folder, class_name)\n",
    "            if os.path.isdir(class_folder):\n",
    "                for image_name in os.listdir(class_folder):\n",
    "                    image_path = os.path.join(class_folder, image_name)\n",
    "                    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "                    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(class_to_idx[class_name])\n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    train_folder = 'data/train'\n",
    "    test_folder = 'data/test'\n",
    "    \n",
    "    X_train, y_train = load_images_from_folder(train_folder)\n",
    "    X_test, y_test = load_images_from_folder(test_folder)\n",
    "    \n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test), num_classes\n",
    "\n",
    "def load_plantvillage():\n",
    "    \"\"\"Load the PlantVillage dataset.\"\"\"\n",
    "    dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
    "    train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "    def normalize_img(image, label):\n",
    "        \"\"\"Normalizes images to [0, 1].\"\"\"\n",
    "        return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "    train_dataset = train_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset, info.features['label'].num_classes\n",
    "\n",
    "def load_cifar10():\n",
    "    \"\"\"Load CIFAR-10 dataset.\"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    return (X_train, y_train), (X_test, y_test), 10\n",
    "\n",
    "def load_cifar100():\n",
    "    \"\"\"Load CIFAR-100 dataset.\"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    return (X_train, y_train), (X_test, y_test), 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading functions\n",
    "datasets_dict = {\n",
    "    'plantdoc': load_plantdoc#,\n",
    "    #'plantvillage': load_plantvillage#,\n",
    "    #'cifar10': load_cifar10,\n",
    "    #'cifar100': load_cifar100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "def create_simple_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_resnet50(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape=input_shape)\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_vgg16(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.VGG16(include_top=False, weights=None, input_shape=input_shape)\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_densenet121(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.DenseNet121(include_top=False, weights=None, input_shape=input_shape)\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_qcnn(input_shape, num_classes):\n",
    "    \"\"\"Quantum CNN using PennyLane.\"\"\"\n",
    "    dev = qml.device('default.qubit', wires=4)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(inputs, weights):\n",
    "        qml.templates.AngleEmbedding(inputs, wires=range(4))\n",
    "        qml.templates.StronglyEntanglingLayers(weights, wires=range(4))\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(4)]\n",
    "\n",
    "    n_qubits = 4\n",
    "    q_depth = 2\n",
    "    weight_shapes = {\"weights\": (q_depth, n_qubits, 3)}\n",
    "\n",
    "    qcnn_model = qml.qnn.KerasLayer(circuit, weight_shapes, output_dim=num_classes)\n",
    "    cnn_model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(n_qubits),\n",
    "        qcnn_model,\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models\n",
    "models_dict = {\n",
    "    'simple_cnn': create_simple_cnn,\n",
    "    'resnet50': create_resnet50,\n",
    "    'vgg16': create_vgg16,\n",
    "    'densenet121': create_densenet121,\n",
    "    'qcnn': create_qcnn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for hyperparameter optimization using Optuna\n",
    "def objective(trial):\n",
    "    dataset_name = trial.suggest_categorical('dataset', list(datasets_dict.keys()))\n",
    "    model_name = trial.suggest_categorical('model', list(models_dict.keys()))\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test), num_classes = datasets_dict[dataset_name]()\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    # Instantiate the selected model\n",
    "    model = models_dict[model_name](input_shape, num_classes)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 15:06:35,175] A new study created in memory with name: no-name-7ac3b24c-a4b0-41c3-8462-92ca751ac9ef\n",
      "/tmp/ipykernel_11599/2744277618.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print best trial details\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/sdp/.venv/lib/python3.8/site-packages/optuna/study/study.py:157\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/sdp/.venv/lib/python3.8/site-packages/optuna/storages/_in_memory.py:234\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    231\u001b[0m best_trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mbest_trial_id\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trials are completed yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mdirections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "# Print best trial details\n",
    "print(\"Best Trial:\")\n",
    "print(\" Value:\", study.best_trial.value)\n",
    "print(\" Params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training plot\n",
    "fig, ax = plt.subplots()\n",
    "optuna.visualization.plot_optimization_history(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
